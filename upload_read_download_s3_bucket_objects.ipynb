{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload, Read, Download and Delete S3 Bucket objects/files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To configure IAM\n",
    "\n",
    "- __*Get Access Key ID and Secret Access Key*__\n",
    "     - After logging in AWS account, in the AWS Console, in the top search bar, enter __*IAM*__ (iam)\n",
    "     - You will see related options. Select __*'IAM'*__ box. It is easily understandable which one to select.\n",
    "     - In the left panel, select __*Users*__\n",
    "     - In the top-right, click on the button __*Add users*__\n",
    "     - In the __*User name*__ box, enter the name.\n",
    "     - In the __*Select AWS credential type*__, select any or both the checkboxes as per your business requirements. I am selecting the 1st checkbox.\n",
    "     - In th left-right, click on the __*Next: Permissions*__ button.\n",
    "     - Under __*Set permissions*__, click on the __*Create Group button*__\n",
    "     - In the __*Group name*__ box, give the group name and then select one of the policy checkbox to have control over access. I am selecting __*AdministratorAccess*__\n",
    "     - In the left-right, click on the __*Create Group button*__\n",
    "     - In the lft-right, click on the __*Next: Tags*__, then __*Next: Review*__, then __*Create user*__\n",
    "     - Finally, you will the __*Access Key ID*__ and __*Secret Key*__. You can copy paste this data.\n",
    "     - You can even download CSV for the keys. This should not be shared with anyone. It should be confidential.\n",
    "     - We will need these keys to create buckets and add objects/files in it.\n",
    "     \n",
    "- __*Configure IAM user*__\n",
    "     - After getting __*Access Key ID*__ and __*Secret Access Key*__, in the CMD or anaconda prompt, type __*aws configure*__\n",
    "     - It will ask __*Access Key ID*__, __*Secret Access Key*__, __*Region Name*__ and __*Output Format*__, give them all.\n",
    "     \n",
    "##### Refer to the video: https://www.youtube.com/watch?v=qGS9UiCFVbo&ab_channel=AWSMadeEasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 dummy dataframe to upload to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandeep</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandy</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maddy</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name age\n",
       "0  sandeep  25\n",
       "1    sandy  22\n",
       "2    maddy  26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy_1 = pd.DataFrame({'name':['sandeep', 'sandy', 'maddy'],\n",
    "                            'age':['25','22','26']})\n",
    "\n",
    "df_dummy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sam</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sammy</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maddy</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name age\n",
       "0    sam  21\n",
       "1  sammy  23\n",
       "2  maddy  24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy_2 = pd.DataFrame({'name':['sam', 'sammy', 'maddy'],\n",
    "                            'age':['21','23','24']})\n",
    "\n",
    "df_dummy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save both files to our local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying only CSV files...\n",
      "['dummy_1.csv', 'dummy_2.csv', 'new_user_credentials.csv']\n"
     ]
    }
   ],
   "source": [
    "df_dummy_1.to_csv('dummy_1.csv', index=False)\n",
    "df_dummy_2.to_csv('dummy_2.csv', index=False)\n",
    "\n",
    "print('Displaying only CSV files...')\n",
    "print([i for i in os.listdir() if i.split('.')[-1]=='csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Access Key ID and Secret Access Key from the downloaded csv while configuring IAM user\n",
    "    - To configure, IAM, refer the 1st marked down cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keys = pd.read_csv('new_user_credentials.csv')\n",
    "\n",
    "# getting access key id and secret access key\n",
    "access_key_id = df_keys['Access key ID'][0]\n",
    "secret_access_key = df_keys['Secret access key'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating boto3 resource instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the s3 service with credentials and info\n",
    "s3_boto = boto3.resource(service_name='s3',\n",
    "                         region_name='us-east-1',\n",
    "                         aws_access_key_id=access_key_id,\n",
    "                         aws_secret_access_key=secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the buckets we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket(name='first-bucket-555')\n"
     ]
    }
   ],
   "source": [
    "for b in s3_boto.buckets.all():\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have only one bucket with the name first-bucket-555. We will upload files to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading files to s3 bucket first-bucket-555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the bucket\n",
    "bucket_select = s3_boto.Bucket('first-bucket-555')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have any objects/files in it\n",
    "\n",
    "for f in bucket_select.objects.all():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It printed nothing, meaning no files in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_select is the instance for selected bucket created above\n",
    "\n",
    "# uploading dummy_1 file\n",
    "bucket_select.upload_file(Filename='dummy_1.csv', Key='s3_dummy_1.csv')\n",
    "\n",
    "# uploading dummy_2 file\n",
    "bucket_select.upload_file(Filename='dummy_2.csv', Key='s3_dummy_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='first-bucket-555', key='s3_dummy_1.csv')\n",
      "s3.ObjectSummary(bucket_name='first-bucket-555', key='s3_dummy_2.csv')\n"
     ]
    }
   ],
   "source": [
    "# Now check if we have any objects/files in it\n",
    "\n",
    "for f in bucket_select.objects.all():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 objects/files created inside the first-bucket-555."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete one of the files from the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'A9JMQE6PDB47JR09',\n",
       "  'HostId': 'egfFX+krb8SQe0r2o9qZxA99TM53/AWBDRB8T2di8ttp+7FhsqWHwMCXK1BOnhoiXiqiqTlL/cE=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'egfFX+krb8SQe0r2o9qZxA99TM53/AWBDRB8T2di8ttp+7FhsqWHwMCXK1BOnhoiXiqiqTlL/cE=',\n",
       "   'x-amz-request-id': 'A9JMQE6PDB47JR09',\n",
       "   'date': 'Tue, 14 Dec 2021 12:44:35 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the bucket\n",
    "bucket_select = s3_boto.Bucket('first-bucket-555')\n",
    "\n",
    "bucket_select.Object('s3_dummy_2.csv').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='first-bucket-555', key='s3_dummy_1.csv')\n"
     ]
    }
   ],
   "source": [
    "# Now check if we have any objects/files in it\n",
    "\n",
    "for f in bucket_select.objects.all():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deleted s3_dummy_2.csv object from the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the files from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the bucket\n",
    "bucket_select = s3_boto.Bucket('first-bucket-555')\n",
    "\n",
    "# get s3_dummy_1 and save in local\n",
    "obj = bucket_select.Object('s3_dummy_1.csv').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'KJYQ653RG4X7D9D9',\n",
       "  'HostId': 'Js3kL0gEz7C8A3LajvI+xx85uF1LYLvJxv3NvutTKB8yBuuCixXLT+NwZ84gZ5i6EicuYWh23l4=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Js3kL0gEz7C8A3LajvI+xx85uF1LYLvJxv3NvutTKB8yBuuCixXLT+NwZ84gZ5i6EicuYWh23l4=',\n",
       "   'x-amz-request-id': 'KJYQ653RG4X7D9D9',\n",
       "   'date': 'Tue, 14 Dec 2021 12:47:31 GMT',\n",
       "   'last-modified': 'Tue, 14 Dec 2021 12:38:58 GMT',\n",
       "   'etag': '\"11bcd569cbd8205402394ecaf557ee4b\"',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'content-type': 'binary/octet-stream',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '42'},\n",
       "  'RetryAttempts': 0},\n",
       " 'AcceptRanges': 'bytes',\n",
       " 'LastModified': datetime.datetime(2021, 12, 14, 12, 38, 58, tzinfo=tzutc()),\n",
       " 'ContentLength': 42,\n",
       " 'ETag': '\"11bcd569cbd8205402394ecaf557ee4b\"',\n",
       " 'ContentType': 'binary/octet-stream',\n",
       " 'Metadata': {},\n",
       " 'Body': <botocore.response.StreamingBody at 0x28c547bee80>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our data is inside the key Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandeep</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandy</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maddy</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0  sandeep   25\n",
       "1    sandy   22\n",
       "2    maddy   26"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_get = pd.read_csv(obj['Body'])\n",
    "\n",
    "df_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the file from the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying only CSV files...\n",
      "['dummy_1.csv', 'dummy_2.csv', 'new_user_credentials.csv']\n"
     ]
    }
   ],
   "source": [
    "# check the csv files we have in our local\n",
    "print('Displaying only CSV files...')\n",
    "print([i for i in os.listdir() if i.split('.')[-1]=='csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandeep</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandy</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maddy</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0  sandeep   25\n",
       "1    sandy   22\n",
       "2    maddy   26"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the bucket\n",
    "bucket_select = s3_boto.Bucket('first-bucket-555')\n",
    "\n",
    "# download and save in our local\n",
    "bucket_select.download_file(Key='s3_dummy_1.csv', Filename='dummy_1_downloaded.csv')\n",
    "\n",
    "df_download = pd.read_csv('dummy_1_downloaded.csv')\n",
    "df_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying only CSV files...\n",
      "['dummy_1.csv', 'dummy_1_downloaded.csv', 'dummy_2.csv', 'new_user_credentials.csv']\n"
     ]
    }
   ],
   "source": [
    "# check the csv files we have in our local\n",
    "print('Displaying only CSV files...')\n",
    "print([i for i in os.listdir() if i.split('.')[-1]=='csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### File dummy_1.csv downloaded and saved as dummy_1_downloaded.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
